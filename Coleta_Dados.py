# -*- coding: utf-8 -*-
"""Coleta_Dados_Previsao_do_Tempo_GIT

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1liWrbxtIBJY2UV3IJwsH1YI4PKu7LO47

> **Para os dados individuais**
1. Fazer a conexão com o Big Query
2. Extrair os dados históricos desejados no bigquery
3. Extrair os dados atuais desejados
4. Fazer ajustes e padronizações nos dados
5. Inserir os dados atuais na base histórica (considerando apenas o que for novo)
6. Subir a nova tabela para o Big Query
7. Conectar o Power BI ao Big Query para realização das análises
8. Tornar esse processo automático para ser executado todos os dias as 12h (servidor)
"""

import pandas_gbq #Conexão com o Bigquery pelo Pandas
import pandas as pd # Pacote pandas tradicional
from google.oauth2 import service_account #Conexão com Google Cloud

COPES = [
    'https://www.googleapis.com/auth/cloud-platform'
]

credentials = service_account.Credentials.from_service_account_info(
{
  "type": "service_account",
  "project_id": "xxxxxxxxxxxxxx",
  "private_key_id": "xxxxxxxxxxxxx",
  "private_key": "xxxxxxxx",
  "client_email": "appoutside@xxxxxxxxxxxxxx.iam.gserviceaccount.com",
  "client_id": "xxxxxxxxxxxxxxxxxxxxxxx",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/appoutside%40xxxxxxxxxxxxxx.iam.gserviceaccount.com",
  "universe_domain": "googleapis.com"
}
)

pandas_gbq.context.credentials = credentials
pandas_gbq.context.project = "xxxxxxxxxxxxxx"

Base_temp = pd.read_gbq('Projeto_eduardo.Temperatura', project_id='fluent-observer-386614')
Base_temp

""">**Inserindo dados do dia**"""

import requests
from bs4 import BeautifulSoup
from datetime import date
import pandas as pd
import pandas_gbq

# URL do site que você deseja acessar
url = "https://www.climatempo.com.br/previsao-do-tempo/cidade/365/santacruzdosul-rs"

# Faz a requisição HTTP GET para obter o conteúdo HTML
response = requests.get(url)

# Verifica se a requisição foi bem-sucedida (código 200 indica sucesso)
if response.status_code == 200:
    # Obtém o conteúdo HTML da resposta
    html_content = response.text
    
    # Cria um objeto BeautifulSoup para analisar o HTML
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # Encontra todos os elementos que possuem a classe "_flex"
    elements = soup.find_all(class_="-gray _flex _align-center")
    
    # Verifica se foram encontrados elementos
    if elements:
        # Obtém a data atual
        data_atual = date.today().strftime("%d/%m/%Y")
        
        # Lista para armazenar as informações
        info = []
        
        # Itera sobre os elementos encontrados
        for element in elements:
            # Extrai as informações desejadas do elemento
            temp_max_elem = element.find(id="max-temp-1")
            temp_min_elem = element.find(id="min-temp-1")
            
            # Verifica se as temperaturas foram encontradas
            if temp_max_elem and temp_min_elem:
                # Extrai os valores das temperaturas
                temp_max = temp_max_elem.text.strip()
                temp_min = temp_min_elem.text.strip()
                
                # Verifica se as temperaturas são diferentes de "None"
                if temp_max and temp_min:
                    # Adiciona as informações à lista
                    info.append([data_atual, temp_max, temp_min])
        
        # Cria um DataFrame a partir da lista de informações
        temp_now = pd.DataFrame(info, columns=["data", "temp_max", "temp_min"])
        
        # Imprime o DataFrame
        print(temp_now)
        
      
    else:
        print("Nenhum elemento encontrado com a classe '_flex'")
else:
    print("Erro ao fazer a requisição:", response.status_code)

# Concatenando 
tempo_final = pd.concat([temp_now, Base_temp]).reset_index()
tempo_final['data'] = pd.to_datetime(tempo_final['data'], dayfirst = True)

#Remover valores duplicados
tempo_final = tempo_final.drop_duplicates(subset=['data'])

pandas_gbq.to_gbq(tempo_final, 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', project_id='xxxxxxxxxxxxxxxxxxxxxx', if_exists='replace')
print(tempo_final)

Base_temp = pd.read_gbq('Projeto_eduardo.Temperatura', project_id='fluent-observer-386614')
Base_temp
